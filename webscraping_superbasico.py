# -*- coding: utf-8 -*-
"""webscraping_superbasico_Flora.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zPUH-o9QyNv0qurL5DB1NtCB39J96Rt5
"""

#Este é um código super básico que extrai noticias da página principal do NDMais Florianopolis
#Foi feito no Colab

# -*- coding: utf-8 -*-
#"""WebScraping-superBasico.ipynb

#Automatically generated by Colaboratory.

import requests # para requisições http
import json # para gerar JSON a partir de objetos do Python
from bs4 import BeautifulSoup # BeautifulSoup é uma biblioteca Python de extração de dados de arquivos HTML e XML.
from google.colab import files #importei esse pacote para fazer o download do arquivo JSON gerado

requisicaoDePagina = requests.get('https://www.gov.br/inpe/pt-br/assuntos/ultimas-noticias')

conteudo = requisicaoDePagina.content

#mostra o tipo Pyhton da página
print(type(requisicaoDePagina.content))

#joga para a variável site todo o conteúdo da página passada pelo requests.get()
site = BeautifulSoup(conteudo, 'html.parser')

#imprime o site inteiro, como o original
#print(site)

#joga para a variável noticias todos os elementos "article", que é onde está cada uma das manchetes do site princial
noticias = site.findAll("div",{"class":"conteudo"})

#imprime tipo Python de noticias
print(type(noticias))


#cria uma variável do tipo lista para guardar os dados em um JSON
resposta = []
#cria uma variável para numerar as noticias
noticia_nr = 1

print(f"Temos no total {len(noticias)} noticias nesta pagina")

from dateutil.parser import parse

#faz um laço na lista noticias (no plural), atribuindo cada item da lista para a variável noticia (no singular)
for noticia in noticias:

  #encontra nas tags do HTMO título, resumo e onde está publicada cada uma das noticias, e joga para as respectivas variáveis
  categoria = noticia.find("div",{"class":"categoria-noticia"})
  titulo = noticia.find("h2", {"class" : "titulo"})
  resumo = noticia.find("span",{"class" : "descricao"})
  data = noticia.find("span",{"class" : "data"})

  #joga o texto de cada uma das tags
  cat = categoria.text
  tit = titulo.text.strip()
  resumo = descricao.text.strip().split("\n", 1)[1].strip().replace("-", "").strip()
  dat = data.text.strip()
  #printando para verificar
  print(noticia_nr)
  print("Categoria:", cat)
  print("Título:", tit)
  print("Resumo:", resumo)
  print("Data:", dat)
  #como pode não haver resumo em algumas notícias, é feito um teste.
  if resumo:
    print("Resumo:", resumo)
  else:
    resumo = "Sem resumo"
    print(resumo)

  #um print para separa as noticias
  print("....")

  # Cria uma espécie de dicionario para depois jogar para o JSON
  dados = {'NUMERO': str(noticia_nr),'CATEGORIA':cat, 'TITULO': tit, 'RESUMO': resumo, 'DATA': dat}

  # Pendura o dicionario em uma lista e incrementa a variável que conta o número de noticias
  resposta.append(dados)
  noticia_nr += 1

#final do laço que percorre a lista de notícias

#apenas dois prints para mostrar o tipo da resposta e a resposta transformada em string
print("Tipo da resposta", type(resposta))
print(' '.join(map(str, resposta)))

# Converte os objetos Pyhton em objeto JSON e exporta para o noticias.json
with open('noticias_Flora.json', 'w') as arquivo:
  arquivo.write(str(json.dumps(resposta, indent=4)))
print("Created Json File")

#faz o download usando a boblioteca do Colab
files.download('noticias_Flora.json')